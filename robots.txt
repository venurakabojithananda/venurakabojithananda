# robots.txt for Venuraka Bojith Ananda English Classes
# https://venurakabojithananda.github.io/

# Allow all search engines to crawl everything
User-agent: *
Allow: /
Disallow: 

# Tell search engines where to find your sitemap
Sitemap: https://venurakabojithananda.github.io/sitemap.xml

# Specific rules for different search engines
User-agent: Googlebot
Allow: /
Allow: /*.pdf$
Allow: /*.jpg$
Allow: /*.png$
Allow: /$

User-agent: Googlebot-Image
Allow: /*.jpg$
Allow: /*.png$
Allow: /*.gif$
Allow: /me.jpg

User-agent: Googlebot-Video
Allow: /
Allow: /*youtube*
Allow: /*embed*

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp  # Yahoo
Allow: /
Crawl-delay: 1

User-agent: Baiduspider  # China
Allow: /
Crawl-delay: 2

User-agent: Yandex  # Russia
Allow: /
Crawl-delay: 2

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

# Host directive (helps with canonical URLs)
Host: https://venurakabojithananda.github.io

# Crawl delay for all other bots
Crawl-delay: 1

# Important pages that should be prioritized
Allow: /$
Allow: /index.html$
Allow: /me.jpg$
Allow: /*.pdf$
